{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1466c028",
   "metadata": {},
   "source": [
    "%%markdown\n",
    "# Dataset Generation Template\n",
    "\n",
    "This notebook provides a template for generating and uploading new datasets to MLflow, after you have the raw scraped data.\n",
    "\n",
    "## Data Format\n",
    "\n",
    "Your data needs to be organized in a dictionary with three required keys:\n",
    "- `inputs`: Feature matrix as NumPy array\n",
    "- `target`: Binary target matrix as NumPy array\n",
    "- `target_names`: List of strings naming each target feature\n",
    "\n",
    "### Shape Requirements\n",
    "\n",
    "| Component | Type | Shape | Description | Example |\n",
    "|-----------|------|-------|-------------|----------|\n",
    "| `inputs` | `np.ndarray` | `(n_samples, n_features)` | Each row is one sample, each column a feature | `(1000, 10)` for 1000 samples with 10 features |\n",
    "| `target` | `np.ndarray` | `(n_samples, n_targets)` | Binary matrix where each column represents one target | `(1000, 3)` for 1000 samples with 3 possible targets |\n",
    "| `target_names` | `list[str]` | `(n_targets,)` | Names for each target column | `[\"cat\", \"dog\", \"bird\"]` for 3 targets |\n",
    "\n",
    "## Example\n",
    "\n",
    "```python\n",
    "data = {\n",
    "    \"inputs\": np.array([\n",
    "        [0.1, 0.2, 0.3],  # Sample 1 with 3 features\n",
    "        [0.4, 0.5, 0.6],  # Sample 2 with 3 features\n",
    "        # ... more samples\n",
    "    ]),\n",
    "    \"target\": np.array([\n",
    "        [1, 0],  # Sample 1: positive for target 1, negative for target 2\n",
    "        [0, 1],  # Sample 2: negative for target 1, positive for target 2\n",
    "        # ... more samples\n",
    "    ]),\n",
    "    \"target_names\": [\"group_A\", \"group_B\"]  # Names for the two target columns\n",
    "}\n",
    "```\n",
    "\n",
    "## Uploading the dataset\n",
    "Once your data is prepared, use `upload_dataset()` to save it to MLflow.\n",
    "This will verify that the data is formatted correctly and then upload it to the server.\n",
    "\n",
    "```python\n",
    "upload_dataset(\n",
    "    data=data,\n",
    "    dataset_name=\"ftir_no_bonding_effects\",  # Broader dataest for which we can have multiple versions\n",
    "    version_name=\"initial_data\",  # Description of this version\n",
    "    description=\"FTIR dataset downloaded from the FCGFormer paper without any modifications\"  # Optional details\n",
    ")\n",
    "```\n",
    "\n",
    "## Accessing the Dataset\n",
    "\n",
    "After upload, the dataset will be available in MLflow for model training with:\n",
    "- NumPy arrays saved as `.npy` files\n",
    "- Target names and counts (number of positive examples) in text files\n",
    "- The code of this notebook saved for reproducability (so you don't have to upload it anywhere)\n",
    "\n",
    "You can view your dataset in MLflow by opening the link printed after calling `upload_dataset()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d458a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: mlflow in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (2.21.1)\n",
      "Requirement already satisfied: ipynbname in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (2024.1.0.0)\n",
      "Requirement already satisfied: requests in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: mlflow-skinny==2.21.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (2.21.1)\n",
      "Requirement already satisfied: Flask<4 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (3.8)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: pandas<3 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow) (2.0.40)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (0.52.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (1.32.1)\n",
      "Requirement already satisfied: packaging<25 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (2.11.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (6.0.2)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (4.12.2)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from mlflow-skinny==2.21.1->mlflow) (0.34.2)\n",
      "Requirement already satisfied: ipykernel in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipynbname) (6.29.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: Mako in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pandas<3->mlflow) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: appnope in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (1.8.8)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (8.29.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (6.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (6.4.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipykernel->ipynbname) (5.14.3)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.1->mlflow) (2.39.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==2.21.1->mlflow) (0.46.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.1->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.1->mlflow) (3.21.0)\n",
      "Requirement already satisfied: decorator in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->ipynbname) (4.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->ipynbname) (4.3.6)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.1->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.1->mlflow) (0.53b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.1->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.1->mlflow) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.1->mlflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: h11>=0.8 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==2.21.1->mlflow) (0.14.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.1->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.1->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.1->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.1->mlflow) (4.9.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->ipynbname) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->ipynbname) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->ipynbname) (0.2.13)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.1->mlflow) (4.6.2.post1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->ipynbname) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->ipynbname) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->ipynbname) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.1->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/jekabsgritans/miniconda3/envs/ml/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.1->mlflow) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# This cell defines upload_dataset. You can ignore it.\n",
    "\n",
    "# Install required packages for `upload_dataset()`\n",
    "%pip install numpy mlflow ipynbname requests\n",
    "\n",
    "import os\n",
    "import urllib.parse\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "import jupyter_client\n",
    "try:\n",
    "    from notebook import notebookapp\n",
    "except ImportError:\n",
    "    from jupyter_server import serverapp as notebookapp\n",
    "\n",
    "# MLFlow creds\n",
    "MLFLOW_DOMAIN = \"mlflow.gritans.lv\"\n",
    "MLFLOW_USERNAME = \"data_user\"\n",
    "MLFLOW_PASSWORD = \"ais7Rah2foo0gee9\"\n",
    "MLFLOW_TRACKING_URI = f\"https://{MLFLOW_DOMAIN}\"\n",
    "\n",
    "parsed_uri = urllib.parse.urlparse(MLFLOW_TRACKING_URI)\n",
    "auth_uri = parsed_uri._replace(\n",
    "    netloc=f\"{urllib.parse.quote(MLFLOW_USERNAME)}:{urllib.parse.quote(MLFLOW_PASSWORD)}@{parsed_uri.netloc}\"\n",
    ").geturl()\n",
    "\n",
    "mlflow.set_tracking_uri(auth_uri)\n",
    "\n",
    "\n",
    "def upload_dataset(\n",
    "    data: Dict[str, Any],\n",
    "    dataset_name: str,\n",
    "    version_name: str,\n",
    "    description: str | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (Dict[str, Any]): Dictionary containing the dataset with keys:\n",
    "            - \"inputs\": NumPy array of shape (num_samples, num_input_features)\n",
    "            - \"target\": NumPy array of shape (num_samples, num_output_features)\n",
    "            - \"target_names\": List of target feature names, in the same order as the target array.\n",
    "        dataset_name (str): Name of the dataset.\n",
    "        version_name (str): A descriptive version name for the dataset. Doesn't need to be unique, just for reference.\n",
    "        description (str): An (optional) description of this dataset version.\n",
    "    \"\"\"\n",
    "    # Check dictionary\n",
    "    expected_keys = {\"inputs\", \"target\", \"target_names\"}\n",
    "    assert set(data.keys()) == expected_keys, (\n",
    "        f\"Invalid dataset format. Keys should be {expected_keys}.\"\n",
    "    )\n",
    "\n",
    "    # Check expected types\n",
    "    assert isinstance(data[\"inputs\"], np.ndarray), (\n",
    "        f\"Inputs must be a numpy.ndarray. Got {type(data['inputs'])}.\"\n",
    "    )\n",
    "    assert isinstance(data[\"target\"], np.ndarray), (\n",
    "        f\"Targets must be a numpy.ndarray. Got {type(data['target'])}.\"\n",
    "    )\n",
    "    assert isinstance(data[\"target_names\"], list), (\n",
    "        f\"target names must be a list. Got {type(data['target_names'])}.\"\n",
    "    )\n",
    "    assert all(isinstance(name, str) for name in data[\"target_names\"]), (\n",
    "        \"All target names must be strings.\"\n",
    "    )\n",
    "\n",
    "    # Check expected shapes\n",
    "    inputs: np.ndarray = data[\"inputs\"]\n",
    "    target: np.ndarray = data[\"target\"]\n",
    "    target_names = data[\"target_names\"]\n",
    "\n",
    "    assert inputs.ndim == 2, (\n",
    "        f\"Inputs must be a (num_samples, num_input_features) array. \"\n",
    "        f\"Got {inputs.ndim} dimensions.\"\n",
    "    )\n",
    "    assert target.ndim == 2, (\n",
    "        f\"Targets must be a (num_samples, num_output_features) array. \"\n",
    "        f\"Got {target.ndim} dimensions.\"\n",
    "    )\n",
    "\n",
    "    n_samples = inputs.shape[0]\n",
    "    assert n_samples > 0, (\n",
    "        f\"Inputs must have at least one sample. Got {n_samples} samples.\"\n",
    "    )\n",
    "    assert n_samples == target.shape[0], (\n",
    "        f\"Inputs and targets must have the same number of samples. \"\n",
    "        f\"Got {n_samples} inputs and {target.shape[0]} targets.\"\n",
    "    )\n",
    "\n",
    "    n_outputs = target.shape[1]\n",
    "    assert n_outputs > 0 and n_outputs == len(target_names), (\n",
    "        f\"Targets must have the same number of features as target names. \"\n",
    "        f\"Got {n_outputs} target features and {len(target_names)} target names.\"\n",
    "    )\n",
    "\n",
    "    # Compute number of positive samples per target\n",
    "    pos_counts = target.sum(axis=0)\n",
    "\n",
    "    mlflow.set_experiment(experiment_name=dataset_name)\n",
    "    with mlflow.start_run(run_name=version_name) as run:\n",
    "        local_dir = os.path.join(\"./runs\", run.info.run_id)\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Log the notebook generating this dataset\n",
    "  \n",
    "    try:\n",
    "        # primary: ipynbname often just works\n",
    "        import ipynbname\n",
    "        notebook_path = ipynbname.path()\n",
    "\n",
    "    except Exception:\n",
    "        # fallback: query the Jupyter serverâ€™s /api/sessions\n",
    "        # 1) get your kernel id\n",
    "        conn_file = jupyter_client.find_connection_file()\n",
    "        kernel_id = os.path.basename(conn_file).split('-', 1)[1].split('.')[0]\n",
    "\n",
    "        # 2) iterate over all running notebook servers\n",
    "        for srv in notebookapp.list_running_servers():\n",
    "            # build the URL for sessions\n",
    "            url = srv['url'].rstrip('/') + '/api/sessions'\n",
    "            token = srv.get('token', '')\n",
    "            params = {'token': token} if token else {}\n",
    "\n",
    "            try:\n",
    "                resp = requests.get(url, params=params)\n",
    "                resp.raise_for_status()\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            # 3) look for our kernel in their active sessions\n",
    "            for sess in resp.json():\n",
    "                if sess['kernel']['id'] == kernel_id:\n",
    "                    # 4) reconstruct the full path\n",
    "                    rel_path = sess['notebook']['path']       # e.g. \"subdir/MyNotebook.ipynb\"\n",
    "                    notebook_path = os.path.join(srv['notebook_dir'], rel_path)\n",
    "                    break\n",
    "            else:\n",
    "                continue\n",
    "            break\n",
    "        else:\n",
    "            raise RuntimeError(\"Could not locate the current notebook path\")\n",
    "\n",
    "        filename = os.path.basename(notebook_path)\n",
    "        mlflow.log_artifact(notebook_path, filename)\n",
    "\n",
    "        # Log the dataset\n",
    "        inputs_path = os.path.join(local_dir, \"inputs.npy\")\n",
    "        target_path = os.path.join(local_dir, \"target.npy\")\n",
    "        target_names_path = os.path.join(local_dir, \"target_names.txt\")\n",
    "        pos_counts_path = os.path.join(local_dir, \"pos_counts.txt\")\n",
    "\n",
    "        ## save locally\n",
    "        np.save(inputs_path, inputs)\n",
    "        np.save(target_path, target)\n",
    "\n",
    "        with open(target_names_path, \"w\") as f:\n",
    "            for name in target_names:\n",
    "                f.write(f\"{name}\\n\")\n",
    "\n",
    "        with open(pos_counts_path, \"w\") as f:\n",
    "            for i, count in enumerate(pos_counts):\n",
    "                f.write(f\"{target_names[i]}: {count}\\n\")\n",
    "\n",
    "        ## upload to mlflow\n",
    "        mlflow.log_artifact(inputs_path)\n",
    "        mlflow.log_artifact(target_path)\n",
    "        mlflow.log_artifact(target_names_path)\n",
    "        mlflow.log_artifact(pos_counts_path)\n",
    "\n",
    "        # Log parameters for browsing\n",
    "        mlflow.log_param(\"target_names\", target_names)\n",
    "        mlflow.log_param(\"input_features\", inputs.shape[1])\n",
    "        mlflow.log_param(\"output_features\", target.shape[1])\n",
    "        mlflow.log_param(\"num_samples\", n_samples)\n",
    "\n",
    "        pos_counts_dict = {name: count for name, count in zip(target_names, pos_counts)}\n",
    "        mlflow.log_param(\"pos_counts\", pos_counts_dict)\n",
    "\n",
    "        # Log description\n",
    "        if description:\n",
    "            mlflow.set_tag(\"description\", description)\n",
    "        \n",
    "        # Print MLflow experiment URL\n",
    "        experiment = mlflow.get_experiment_by_name(dataset_name)\n",
    "        if experiment:\n",
    "            print(\"\\nAccess your dataset:\")\n",
    "            print(f\"View dataset at: https://{MLFLOW_USERNAME}:{MLFLOW_PASSWORD}@{MLFLOW_DOMAIN}/#/experiments/{experiment.experiment_id}\")\n",
    "            print(f\"View this version at: https://{MLFLOW_USERNAME}:{MLFLOW_PASSWORD}@{MLFLOW_DOMAIN}/#/experiments/{experiment.experiment_id}/runs/{run.info.run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa7a412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FTIR dataset from all splits...\n",
      "Loading 6342 samples from train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6342/6342 [00:01<00:00, 4125.93sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1387 samples from valid split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading valid: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1387/1387 [00:00<00:00, 2262.90sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 933 samples from test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 933/933 [00:00<00:00, 3430.38sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset statistics:\n",
      "Total samples: 8662\n",
      "Feature dimension: 3602\n",
      "Number of classes: 17\n",
      "Positive samples per class:\n",
      " - alkane: 5986 (69.11%)\n",
      " - methyl: 5557 (64.15%)\n",
      " - alkene: 1165 (13.45%)\n",
      " - alkyne: 227 (2.62%)\n",
      " - alcohols: 2339 (27.00%)\n",
      " - amines: 817 (9.43%)\n",
      " - nitriles: 375 (4.33%)\n",
      " - aromatics: 5018 (57.93%)\n",
      " - alkyl halides: 2405 (27.76%)\n",
      " - esters: 961 (11.09%)\n",
      " - ketones: 787 (9.09%)\n",
      " - aldehydes: 207 (2.39%)\n",
      " - carboxylic acids: 629 (7.26%)\n",
      " - ether: 2155 (24.88%)\n",
      " - acyl halides: 96 (1.11%)\n",
      " - amides: 165 (1.90%)\n",
      " - nitro: 443 (5.11%)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "class_names = [\"alkane\", \"methyl\", \"alkene\", \"alkyne\", \"alcohols\", \"amines\", \"nitriles\", \"aromatics\",\n",
    " \"alkyl halides\", \"esters\", \"ketones\", \"aldehydes\", \"carboxylic acids\", \"ether\",\n",
    " \"acyl halides\", \"amides\", \"nitro\"]\n",
    "\n",
    "# Define the data directory\n",
    "data_dir = \"../data/ftir\"\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "# Initialize arrays to store combined data\n",
    "all_inputs = []\n",
    "all_targets = []\n",
    "\n",
    "# Load data from all splits\n",
    "print(\"Loading FTIR dataset from all splits...\")\n",
    "for split in splits:\n",
    "    split_dir = os.path.join(data_dir, split)\n",
    "    \n",
    "    # Get all sample IDs\n",
    "    npy_paths = glob(os.path.join(split_dir, \"*.npy\"))\n",
    "    ids = [int(os.path.splitext(os.path.basename(path))[0]) for path in npy_paths]\n",
    "    ids.sort()\n",
    "    \n",
    "    print(f\"Loading {len(ids)} samples from {split} split...\")\n",
    "    \n",
    "    # Load each sample\n",
    "    for sample_id in tqdm(ids, desc=f\"Loading {split}\", unit=\"sample\"):\n",
    "        npy_path = os.path.join(split_dir, f\"{sample_id}.npy\")\n",
    "        txt_path = os.path.join(split_dir, f\"{sample_id}.txt\")\n",
    "        \n",
    "        # Load feature vector\n",
    "        x = np.load(npy_path)\n",
    "        \n",
    "        # Load target labels\n",
    "        with open(txt_path, \"r\") as f:\n",
    "            y = np.array([int(tok) for tok in f.read().strip().split()], dtype=np.int32)\n",
    "        \n",
    "        all_inputs.append(x)\n",
    "        all_targets.append(y)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "inputs = np.vstack(all_inputs)  # Stack vertically to create (n_samples, n_features)\n",
    "target = np.vstack(all_targets)  # Stack vertically to create (n_samples, n_classes)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(f\"Total samples: {inputs.shape[0]}\")\n",
    "print(f\"Feature dimension: {inputs.shape[1]}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Positive samples per class:\")\n",
    "for i, name in enumerate(class_names):\n",
    "    count = np.sum(target[:, i])\n",
    "    percent = count / len(target) * 100\n",
    "    print(f\" - {name}: {count} ({percent:.2f}%)\")\n",
    "\n",
    "# Package the data in the required format\n",
    "data = {\n",
    "    \"inputs\": inputs,\n",
    "    \"target\": target,\n",
    "    \"target_names\": class_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4376590e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run combined_splits at: https://data_user:ais7Rah2foo0gee9@mlflow.gritans.lv/#/experiments/6/runs/9660661d08d74b3d90fc3d2ef49fe485\n",
      "ðŸ§ª View experiment at: https://data_user:ais7Rah2foo0gee9@mlflow.gritans.lv/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "# Upload the FTIR dataset to MLflow\n",
    "upload_dataset(\n",
    "    data=data,\n",
    "    dataset_name=\"ftir_complete\",\n",
    "    version_name=\"combined_splits\",\n",
    "    description=\"\"\"\n",
    "    Complete FTIR spectroscopy dataset combined from train, validation, and test splits.\n",
    "    \n",
    "    This dataset contains FTIR (Fourier-transform infrared) spectroscopy data from the FCG-former paper,\n",
    "    with 17 functional group classes. Each sample is labeled with the presence/absence of each functional group.\n",
    "    \n",
    "    Features: FTIR spectra\n",
    "    Targets: Binary labels for 17 functional groups (alkane, methyl, alkene, etc.)\n",
    "    Combined from: train, validation, and test splits\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
